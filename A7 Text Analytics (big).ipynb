{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edd01347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70361fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1298553d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"Hello! How are are? Welcome to python programming\"\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38eae19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', '!', 'How', 'are', 'are', '?', 'Welcome', 'to', 'python', 'programming']\n",
      "['Hello!', 'How are are?', 'Welcome to python programming']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "z= word_tokenize(x)\n",
    "y = sent_tokenize(x)\n",
    "print(z)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0ac730c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python',\n",
       " 'is',\n",
       " 'very',\n",
       " 'good',\n",
       " 'language',\n",
       " 'to',\n",
       " 'implememnt',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'algorithms']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"Python is very good language to implememnt machine learning algorithms\"\n",
    "tokens = nltk.word_tokenize(s)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5777516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk.corpus\n",
    "print(os.listdir(nltk.data.find('corpora')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22928b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47fbab9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3813b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a47d7d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'The', 'King', 'James', 'Bible', ']', 'The', ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bible=nltk.corpus.gutenberg.words('bible-kjv.txt')\n",
    "bible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67df3cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ The King James Bible ] The Old Testament of the King James Bible The First Book of Moses : Called Genesis 1 : 1 In the beginning God created the heaven and the earth . 1 : 2 And the earth was without form , and void ; and darkness was upon the face of the deep . And the Spirit of God moved upon the face of the waters . 1 : 3 And God said , Let there be light : and there was light . 1 : 4 And God saw the light , that it "
     ]
    }
   ],
   "source": [
    "for words in bible[:100]:\n",
    "    print(words,sep=' ', end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d35bcc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP =\"NLP stands for Natural language processing. NLTK is Natural language processing toolkit.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f152002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45f32b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP',\n",
       " 'stands',\n",
       " 'for',\n",
       " 'Natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '.',\n",
       " 'NLTK',\n",
       " 'is',\n",
       " 'Natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'toolkit',\n",
       " '.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "NLP_tokens = word_tokenize(NLP)\n",
    "NLP_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f29d2d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NLP_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a7b6338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "freq = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be255e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'language': 7, 'processing': 7, '.': 7, 'Natural': 7, 'stands': 4, 'for': 4, 'is': 4, 'toolkit': 4, 'NLP': 4, 'NLTK': 4, ...})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for words in NLP_tokens:\n",
    "    freq[words]+=1\n",
    "freq    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d10cb25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq['language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a9dc520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP stands for Natural language processing. NLTK is Natural language processing toolkit.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import blankline_tokenize\n",
    "NLP_blank = blankline_tokenize(NLP)\n",
    "NLP_blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed635d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams, trigrams, ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05a99f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24b7bc51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NLP', 'stands'),\n",
       " ('stands', 'for'),\n",
       " ('for', 'Natural'),\n",
       " ('Natural', 'language'),\n",
       " ('language', 'processing'),\n",
       " ('processing', '.'),\n",
       " ('.', 'NLTK'),\n",
       " ('NLTK', 'is'),\n",
       " ('is', 'Natural'),\n",
       " ('Natural', 'language'),\n",
       " ('language', 'processing'),\n",
       " ('processing', 'toolkit'),\n",
       " ('toolkit', '.')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLP_bigrams=list(nltk.bigrams(NLP_tokens))\n",
    "NLP_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae00b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP_trigrams=list(trigrams(NLP_tokens))\n",
    "NLP_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3268889c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NLP', 'stands', 'for', 'Natural'),\n",
       " ('stands', 'for', 'Natural', 'language'),\n",
       " ('for', 'Natural', 'language', 'processing'),\n",
       " ('Natural', 'language', 'processing', '.'),\n",
       " ('language', 'processing', '.', 'NLTK'),\n",
       " ('processing', '.', 'NLTK', 'is'),\n",
       " ('.', 'NLTK', 'is', 'Natural'),\n",
       " ('NLTK', 'is', 'Natural', 'language'),\n",
       " ('is', 'Natural', 'language', 'processing'),\n",
       " ('Natural', 'language', 'processing', 'toolkit'),\n",
       " ('language', 'processing', 'toolkit', '.')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLP_ngrams=list(ngrams(NLP_tokens,4))\n",
    "NLP_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a6b51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('English'))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "812ed30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP', 'stands', 'for', 'Natural', 'language', 'processing', '.', 'NLTK', 'is', 'Natural', 'language', 'processing', 'toolkit', '.']\n",
      "['NLP', 'stands', 'Natural', 'language', 'processing', '.', 'NLTK', 'Natural', 'language', 'processing', 'toolkit', '.']\n"
     ]
    }
   ],
   "source": [
    "print(NLP_tokens)\n",
    "filtered_sent = []\n",
    "for w in NLP_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sent.append(w)\n",
    "\n",
    "print(filtered_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bcbeb17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP',\n",
       " 'stands',\n",
       " 'Natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '.',\n",
       " 'NLTK',\n",
       " 'Natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'toolkit',\n",
       " '.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sent2=[w for w in NLP_tokens if not w in stop_words]\n",
    "filtered_sent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a75a499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "sample_words = ['Python', 'Pythoning','Pythoner', 'Pythonly','Pythonned']\n",
    "\n",
    "for w in sample_words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e69251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "Train_Text = state_union.raw(\"2005-GWBush.txt\")\n",
    "Sample_Text = state_union.raw(\"2006-GWBush.txt\")\n",
    "customsent_tokenizer = PunktSentenceTokenizer(Train_Text)\n",
    "tokenized = customsent_tokenizer.tokenize(Sample_Text)\n",
    "\n",
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            print(tagged)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "process_content()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
