{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ass2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPDChVsXNJuRf/Xn/fLKwDl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akashsabale01/DSBDA_Lab/blob/main/Ass_No_2_Data_Cleaning_N_Transformation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ass No 2 - Data Wrangling II\n",
        "Create an “Academic performance” dataset of students and perform the following operations using\n",
        "Python.\n",
        "1. Scan all variables for missing values and inconsistencies. If there are missing values and/or\n",
        "inconsistencies, use any of the suitable techniques to deal with them.\n",
        "2. Scan all numeric variables for outliers. If there are outliers, use any of the suitable\n",
        "techniques to deal with them.\n",
        "3. Apply data transformations on at least one of the variables. The purpose of this\n",
        "transformation should be one of the following reasons: to change the scale for better\n",
        "understanding of the variable, to convert a non-linear relation into a linear one, or to\n",
        "decrease the skewness and convert the distribution into a normal distribution.\n",
        "Reason and document your approach properly."
      ],
      "metadata": {
        "id": "I3Z7H_rcOer1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQmR6ssiOLvZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('StudentPerformance.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "RYVa0rIWPbMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use isnull() function to check null values in the dataset.\n",
        "df.isnull()"
      ],
      "metadata": {
        "id": "T3hXIR9EPbOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To create a series true for NaN values for specific columns. \n",
        "# for example math score in dataset and display data with only math score as Nav \n",
        "\n",
        "series = pd.isnull(df['math score'])\n",
        "df[series]"
      ],
      "metadata": {
        "id": "v68E8tMjPbRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filling missing value using fillna() \n",
        "ndf = df\n",
        "ndf.fillna(0)"
      ],
      "metadata": {
        "id": "YZ6b4SomPbVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling null values in dataset \n",
        "#To fill null values in dataset use inplace=true \n",
        "\n",
        "m_v=df ['math score'].mean() \n",
        "df['math score'].fillna(value=m_v, inplace=True) \n",
        "df \n"
      ],
      "metadata": {
        "id": "xNcUXuwwQNT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Following line will replace Nan value in dataframe with value -99 \n",
        "ndf.replace(to_replace = np.nan, value = -99) "
      ],
      "metadata": {
        "id": "DX4ILmGZQNVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To drop rows with at least 1 null value \n",
        "ndf.dropna() "
      ],
      "metadata": {
        "id": "MB3SIbUXQNXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To Drop columns with at least 1 null value. \n",
        "ndf.dropna(axis = 1) "
      ],
      "metadata": {
        "id": "I6tOlS-3SFSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To drop rows with at least 1 null value in csv file. \n",
        "#making new data frame with dropped NA values \n",
        "\n",
        "new_data = ndf.dropna (axis = 0, how ='any') \n",
        "new data "
      ],
      "metadata": {
        "id": "KTWW3G3-SMh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col = ['math score', 'reading score', 'writing score', 'placement score']\n",
        " df.boxplot(col) \n",
        "\n",
        "print(np.where(df['math score']>90))\n",
        "print(np.where(df['reading score' ]<25)) \n",
        "print(np.where(df['writing score' ]<30))"
      ],
      "metadata": {
        "id": "-QviL8ChSMku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-sINmQXoSFVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TpoA3Je6QNbl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}